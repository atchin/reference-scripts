**************************************
11/02/2020 notes--
Files created:
     - "datacleaning_functions.R"

Files edited:
     - "NataneAndrew_NFB+NA_datacleaning_draft.R" [RENAMED from "NataneAndrew_NFB+NA_datacleaning.R"]
     - "Kitsap_KenzieDan.csv" [moved No Site/NFB statuses listed in Description to Title]

Brief:
     - reorganized data and wrote functions

Summary:
     - created a common function for data cleaning all sites
     - tested the multiple vectors in str_detect() - DID NOT WORK, vector was too long compared to the rest of the tbl (figured that would happen)
          - since it was only a few columns, just manually modified the csv...would be interesting to try to create a cleaning function for misplaced data

**************************************
10/26/2020 notes--
Files created:
     - "KenzieDan_datacleaning.R"
     - "Kitsap_KenzieDan.csv" [UPLOADED]
     - "TerryAll.csv" [UPLOADED, w/in "TerryDave" folder]

Files edited:
     - "NataneAndrew_NFB+NA_datacleaning.R" [RENAMED from "NFB+NA_datacleaning.R"]

Brief:
     - theorizing for Kenzie/Dan's data, yet to be run
     - pushed to GitHub

Summary:
     - took a look at Kenzie/Dan's data; not as clean or descriptive as our (Natane/Andrew) data =_=
     - wrote new script to see if str_detect() will take a concatenated vector to search across?
          - we will have to see..
     - Terry's data looks like we can plug and play with the original data cleaning script
     - changes pushed to GitHub so I can play with it on personal comp

Breadcrumbs:
     - check to see if "KenzieDan_datacleaning.R" works as intended
          - go from there if it doesn't
          - mutating multiple str_detect() cols and merging would probably work
     - find way to set wd in RCloud to a local repo?


**************************************
10/19/2020 notes--
Files edited:
     - "NFB+NA_datacleaning.R" [RENAMED from "NFB+NOC_datacleaning.R"]
     - see Github for complete files

Brief:
  - revised with Dan's specs

Summary:
  - showed Dan code. he gave some feedback and revised
  - asked to combine the NFB + NA (No Crossing/Channel) data into a single table
  - also asked to review Dan/Kenzie and Terry/Dave data to see if adjustments need to be made
    - should be minimal

Breadcrumbs:
  - review Dan/Kenzie and Terry/Dave data to see if adjustments to script need to be made


**************************************
10/19/2020 notes--
New files:
  - "old_basefilemanip.R" [RENAMED from "basefilemanip.R"]
  - "NFB+NOC_datacleaning.R" [UPLOADED+EDITED]
  - "OneMoreTime_new.csv" [UPLOADED]
    - Avenza data to play with

Brief:
- writing code for NFB+NOC layers - COMPLETED

Summary:
- working in Atom + RCloud to prep layers for Dan - to be exported to GIS as NFB+NOC layers for the county
- created control flow: wrangled character strings from NFB+NOC data, if-else loop to sort data, then filtered in final .csvs
- checked data for proper sorting - all good!

Breadcrumbs:
- show Dan my code for sorting data


**************************************
09/17/2020 notes--
New files:
  - "basefiledatamanip.R"

imported files:
"DATA MANIP notes.R", "CREATING FUNCTIONS.R", "ggplot2 cheatsheet.R", "LOOP notes.R", "tideyverse cheatsheet.R"

installed packages:
base, tidyverse (ggplot2, tidyr, dplyr, etc.),

Brief:
  - created RCloud account for fish passage data stuff

Summary:
  - created an RCloud account so that I can more easily manipulate csv data for use within ArcGIS
  - created a base script
  - imported notes from laptop hard drive

Breadcrumbs:
  - grab and review Avenza file for common nomenclature to call for in grep (i.e., "NFB")
  - play around with possible ways to extract and write data appropriate for ArcGIS attribute tables
  - write function?
